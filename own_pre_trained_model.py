# -*- coding: utf-8 -*-
"""own pre-trained model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RtXqzELgD2cJAU5n5DFfrmLYgH9bzbXS

The idea is to prepare initial model, train it to recognize masked part of an image and further use to main problem (classification task). It is own pre-trained model and is called self-supervised image inpainting or context prediction.
"""

import os
import collections
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import random
from PIL import Image, ImageDraw
import torch
from torchvision import transforms, datasets
from torch import nn
from torch.utils.data import DataLoader
from sklearn.model_selection import KFold
import math

from google.colab import drive
drive.mount('/content/drive')

# !wget 'https://raw.githubusercontent.com/DWalicki95/foams_microstructure/main/helper_functions.py' -O helper_functions.py
## uncomment when neccessary

from helper_functions import count_files_in_drive, create_dataset
from helper_functions import count_init_transform_shape, print_random_image, show_predicted_mask
from helper_functions import show_transformed_images, cut_img, mask_img
from helper_functions import train_step, test_step, train_and_test
from models_architectures import ContextPredictor


device = 'cuda' if torch.cuda.is_available() else 'cpu' #device agnostic code

DRIVE_PATH = '/content/drive/MyDrive/Pianki'

folder_file_count = {}
zoom = 40
folder_file_count = count_files_in_drive(folder_file_count, zoom, DRIVE_PATH)

folder_file_count = collections.OrderedDict(sorted(folder_file_count.items()))

sum(folder_file_count.values())

"""## Creating dataset"""

data = pd.read_excel('/content/drive/MyDrive/Pianki/Dataset.xlsx', sheet_name='Arkusz2')
data.drop('sample_index', axis=1, inplace=True)

dataset = create_dataset('/content/drive/MyDrive/Pianki', 40, data, '40%_tension') #it is commonly known that mechanical properties are related with microstructure, so here I've chosen 40%_tension BUT
# I've also tested SAG factor (resulting mechanical properties), pHRR and U600 (thermal properties)

rand_img = print_random_image(dataset, return_rand_img=True)

"""# Self-supervised image inpainting"""

test_img = Image.open(dataset['image_path'][5])

im_crop = cut_img(test_img) #function from helper_functions

resized_height, resized_width = count_init_transform_shape(im_crop.height, im_crop.width)
resized_height, resized_width

data_transform = transforms.Compose([
    transforms.Lambda(cut_img),
    transforms.Resize(size=(resized_height, resized_width)),
    transforms.ToTensor()
])

data_mask_transform = transforms.Compose([
    transforms.Lambda(cut_img),
    transforms.Resize(size=(resized_height, resized_width)),
    transforms.Lambda(mask_img),
    transforms.ToTensor()
])

show_transformed_images(list(dataset['image_path']), transform=data_mask_transform)

loss_fn = nn.MSELoss()

"""# Create custom dataset with masked images and original ones."""

class CustomMaskedImageDataset(torch.utils.data.Dataset):
  def __init__(self, paths, transform=None, mask_transform=None):
    self.img_paths = paths
    self.transform = transform
    self.mask_transform = mask_transform

  def __len__(self):
    return len(self.img_paths)

  def __getitem__(self, idx):
    img_path = self.img_paths[idx]
    image = Image.open(img_path).convert('L')

    if self.transform:
      original_image = self.transform(image)
    else:
      original_image = transforms.ToTensor()(image)

    if self.mask_transform:
      masked_image = self.mask_transform(image)
    else:
      masked_image = transforms.ToTensor()(image)

    return masked_image, original_image

data = CustomMaskedImageDataset(dataset['image_path'],
                                transform=data_transform,
                                mask_transform=data_mask_transform)

# plt.imshow(data[3][0].squeeze(), cmap='gray');

dataloader = DataLoader(dataset=data,
                        batch_size=32,
                        num_workers=1,
                        shuffle=True)

# plt.imshow(next(iter(dataloader))[0][7].squeeze(), cmap='gray');

#Training and evaluating model
loss_fn = nn.MSELoss()
n_splits=3
kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)
img_paths = list(dataset['image_path'])
cv_results = {}
split = 0 #param for saving results each corss-val step
actual_best_result = 1 #param for best model choosing

for train_index, test_index in kfold.split(img_paths): #cross-validation

  model = ContextPredictor(input_shape=1, #model initialization
                         hidden_units=16)
  model.apply(model.initialize_weights_xavier) #xavier weights initialization

  train_paths = [img_paths[i] for i in train_index]
  val_images = math.ceil(len(train_paths) * 0.15)
  val_paths = train_paths[-val_images:]
  train_paths = train_paths[:-val_images]
  test_paths = [img_paths[i] for i in test_index]
  split += 1

  train_data = CustomMaskedImageDataset(paths=train_paths, transform=data_transform, mask_transform=data_mask_transform)
  val_data = CustomMaskedImageDataset(paths=val_paths, transform=data_transform, mask_transform=data_mask_transform)
  test_data = CustomMaskedImageDataset(paths=test_paths, transform=data_transform, mask_transform=data_mask_transform)

  train_dataloader = DataLoader(dataset=train_data,
                        batch_size=32,
                        num_workers=1,
                        shuffle=True)
  val_dataloader = DataLoader(dataset=val_data,
                              batch_size=32,
                              num_workers=1,
                              shuffle=False)
  test_dataloader = DataLoader(dataset=test_data,
                               batch_size=32,
                               num_workers=1,
                               shuffle=False)
  # sample_inputs, _ = next(iter(train_dataloader))
  # print(sample_inputs.shape)

  train_loss_list, val_loss_list, epoch_counter = train_and_test(model=model,
                 train_dataloader=train_dataloader,
                 val_dataloader=val_dataloader,
                 test_dataloader=test_dataloader,
                 loss_fn=loss_fn,
                 optimizer='Adam',
                 device=device,
                 save_model_name='inpainting_model',
                 learning_rate=0.001,
                 epochs=80)
  cv_results[f' Train loss: {split}'] = train_loss_list
  cv_results[f' Test loss: {split}'] = val_loss_list

  #choose and save best model
  best_result = np.min(val_loss_list)
  if best_result < actual_best_result:
    actual_best_result = best_result
    torch.save(model.state_dict(), f'_inpainting_model_step_{split}_min_test_loss_{actual_best_result}')

# sample, _ = next(iter(test_dataloader))

show_predicted_mask(1)

