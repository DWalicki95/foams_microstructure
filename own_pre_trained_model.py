# -*- coding: utf-8 -*-
"""own pre-trained model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RtXqzELgD2cJAU5n5DFfrmLYgH9bzbXS

The idea is to prepare initial model, train it to recognize masked part of an image and further use to main problem (classification task). It is own pre-trained model and is called self-supervised image inpainting or context prediction.
"""

import os
import collections
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import random
from PIL import Image, ImageDraw
import torch
from torchvision import transforms, datasets
from torch import nn
from torch.utils.data import DataLoader
from sklearn.model_selection import KFold
import math

from google.colab import drive
drive.mount('/content/drive')

!wget 'https://raw.githubusercontent.com/DWalicki95/foams_microstructure/main/helper_functions.py' -O helper_functions.py

from helper_functions import count_files_in_drive, create_dataset
from helper_functions import count_init_transform_shape, print_random_image
from helper_functions import show_transformed_images
from helper_functions import train_step, test_step, train_and_test

device = 'cuda' if torch.cuda.is_available() else 'cpu' #device agnostic code

DRIVE_PATH = '/content/drive/MyDrive/Pianki'

folder_file_count = {}
zoom = 40 #different microscope maginification
folder_file_count = count_files_in_drive(folder_file_count, zoom, DRIVE_PATH)

folder_file_count = collections.OrderedDict(sorted(folder_file_count.items()))

sum(folder_file_count.values())

"""## Creating dataset"""

data = pd.read_excel('/content/drive/MyDrive/Pianki/Dataset.xlsx', sheet_name='Arkusz2')
data.drop('sample_index', axis=1, inplace=True)

dataset = create_dataset('/content/drive/MyDrive/Pianki', data, '40%_tension') #it is commonly known that mechanical properties are related with microstructure, so here I've chosen 40%_tension BUT
# I've also tested SAG factor (resulting mechanical properties), pHRR and U600 (thermal properties)

rand_img = print_random_image(dataset, return_rand_img=True)

"""# Self-supervised image inpainting"""

test_img = Image.open(dataset['image_path'][5])

def cut_img(image, left=0, top=0, right=1280, bottom=960):
  '''
  Cutting image. Takes input:
    * left = 'x' coordination
    * right = left + img width
    * top = 'y' coordination
    * bottom = top + height
  '''

  return image.crop((left, top, right, bottom))

im_crop = cut_img(test_img)

resized_height, resized_width = count_init_transform_shape(im_crop.height, im_crop.width)
resized_height, resized_width

def mask_img(image, mask_size=(2, 2), masked_places=1, seed=42, mask_return=False):

  '''
  Mask random part of image.
  '''

  height, width = image.size
  masked_image = image.copy()

  for place in range(masked_places):

    random.seed(seed)
    top = np.random.randint(0, height - mask_size[0])
    left = np.random.randint(0, width - mask_size[1])
    bottom = top + mask_size[0]
    right = left + mask_size[1]


    draw = ImageDraw.Draw(masked_image)
    draw.rectangle([left, top, right, bottom], fill=0)

  return masked_image

  if mask_return:
    return masked_image, (left, top, right, bottom)

data_transform = transforms.Compose([
    transforms.Lambda(cut_img),
    transforms.Resize(size=(resized_height, resized_width)),
    transforms.ToTensor()
])

data_mask_transform = transforms.Compose([
    transforms.Lambda(cut_img),
    transforms.Resize(size=(resized_height, resized_width)),
    transforms.Lambda(mask_img),
    transforms.ToTensor()
])

show_transformed_images(list(dataset['image_path']), transform=data_mask_transform)

loss_fn = nn.MSELoss()

"""# Create custom dataset with masked images and original ones."""

class CustomMaskedImageDataset(torch.utils.data.Dataset):
  def __init__(self, paths, transform=None, mask_transform=None):
    self.img_paths = paths
    self.transform = transform
    self.mask_transform = mask_transform

  def __len__(self):
    return len(self.img_paths)

  def __getitem__(self, idx):
    img_path = self.img_paths[idx]
    image = Image.open(img_path).convert('L')

    if self.transform:
      original_image = self.transform(image)
    else:
      original_image = transforms.ToTensor()(image)

    if self.mask_transform:
      masked_image = self.mask_transform(image)
    else:
      masked_image = transforms.ToTensor()(image)

    return masked_image, original_image

data = CustomMaskedImageDataset(dataset['image_path'],
                                transform=data_transform,
                                mask_transform=data_mask_transform)

dataloader = DataLoader(dataset=data,
                        batch_size=32,
                        num_workers=1,
                        shuffle=True)

class ContextPredictor(nn.Module):
  def __init__(self, input_shape, hidden_units):
    super().__init__()

    #encoding layers

    self.conv_block_1 = nn.Sequential(
      nn.Conv2d(in_channels=input_shape,
                    out_channels=hidden_units,
                    kernel_size=3,
                    stride=1,
                    padding=1),
      nn.ReLU(),
      nn.Conv2d(in_channels=hidden_units,
                    out_channels=hidden_units,
                    kernel_size=3,
                    stride=1,
                    padding=1),
      nn.ReLU(),
      nn.Dropout(0.1),
      nn.MaxPool2d(kernel_size=2,
                      stride=2)
      )

    self.conv_block_2 = nn.Sequential(
      nn.Conv2d(in_channels=hidden_units,
                    out_channels=hidden_units,
                    kernel_size=3,
                    stride=1,
                    padding=1),
      nn.ReLU(),
      nn.Conv2d(in_channels=hidden_units,
                    out_channels=hidden_units,
                    kernel_size=3,
                    stride=1,
                    padding=1),
      nn.ReLU(),
      nn.Dropout(0.1),
      nn.MaxPool2d(kernel_size=2,
                      stride=2)
      )

    self.encoder = nn.Sequential(
      self.conv_block_1,
      self.conv_block_2
      )

    #decoding layers

    self.deconv_block_1 = nn.Sequential(
        nn.ConvTranspose2d(in_channels=hidden_units,
                          out_channels=hidden_units,
                          kernel_size=3,
                          stride=2,
                          padding=1,
                          output_padding=1),
        nn.ReLU(),
        nn.ConvTranspose2d(in_channels=hidden_units,
                          out_channels=hidden_units,
                          kernel_size=3,
                          stride=1,
                          padding=1),
        nn.ReLU(),
        nn.Dropout(0.1)
    )

    self.deconv_block_2 = nn.Sequential(
        nn.ConvTranspose2d(in_channels=hidden_units,
                          out_channels=hidden_units,
                          kernel_size=3,
                          stride=2,
                          padding=1,
                          output_padding=1),
        nn.ReLU(),
        nn.ConvTranspose2d(in_channels=hidden_units,
                          out_channels=input_shape,
                          kernel_size=3,
                          stride=1,
                          padding=1)
    )


    self.decoder = nn.Sequential(
      self.deconv_block_1,
      self.deconv_block_2
    )

  @staticmethod #static function, not instanction method
  def initialize_weights_xavier(m):
    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):
      nn.init.xavier_uniform_(m.weight)
      if m.bias is not None: #if layer has a bias
        nn.init.zeros_(m.bias) #set bias to 0


  def forward(self, x):
    x = self.encoder(x)
    # print(x.shape)
    x = self.decoder(x)
    # print(x.shape)

    return x

loss_fn = nn.MSELoss()
n_splits=3
kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)
img_paths = list(dataset['image_path'])
cv_results = {}
split = 0 #param for saving results each corss-val step
actual_best_result = 1 #param for best model choosing

for train_index, test_index in kfold.split(img_paths): #cross-validation

  model = ContextPredictor(input_shape=1, #model initialization
                         hidden_units=16)
  model.apply(model.initialize_weights_xavier) #xavier weights initialization

  train_paths = [img_paths[i] for i in train_index]
  val_images = math.ceil(len(train_paths) * 0.15)
  val_paths = train_paths[-val_images:]
  train_paths = train_paths[:-val_images]
  test_paths = [img_paths[i] for i in test_index]
  split += 1

  train_data = CustomMaskedImageDataset(paths=train_paths, transform=data_transform, mask_transform=data_mask_transform)
  val_data = CustomMaskedImageDataset(paths=val_paths, transform=data_transform, mask_transform=data_mask_transform)
  test_data = CustomMaskedImageDataset(paths=test_paths, transform=data_transform, mask_transform=data_mask_transform)

  train_dataloader = DataLoader(dataset=train_data,
                        batch_size=32,
                        num_workers=1,
                        shuffle=True)
  val_dataloader = DataLoader(dataset=val_data,
                              batch_size=32,
                              num_workers=1,
                              shuffle=False)
  test_dataloader = DataLoader(dataset=test_data,
                               batch_size=32,
                               num_workers=1,
                               shuffle=False)
  # sample_inputs, _ = next(iter(train_dataloader))
  # print(sample_inputs.shape)

  train_loss_list, val_loss_list, epoch_counter = train_and_test(model=model,
                 train_dataloader=train_dataloader,
                 val_dataloader=val_dataloader,
                 test_dataloader=test_dataloader,
                 loss_fn=loss_fn,
                 optimizer='Adam',
                 device=device,
                 save_model_name='inpainting_model',
                 learning_rate=0.001,
                 epochs=80)
  cv_results[f' Train loss: {split}'] = train_loss_list
  cv_results[f' Test loss: {split}'] = val_loss_list

  #choose and save best model
  best_result = np.min(val_loss_list)
  if best_result < actual_best_result:
    actual_best_result = best_result
    torch.save(model.state_dict(), f'_inpainting_model_step_{split}_min_test_loss_{actual_best_result}')

sample, _ = next(iter(test_dataloader))

model.eval()
with torch.no_grad():
  preds = model(sample.to(device))

def show_predicted_mask(index: int = 0):
  plt.figure(figsize=(12, 6))
  plt.subplot(1, 2, 1)
  plt.imshow(sample[index].permute(1, 2, 0).numpy(), cmap='gray')
  plt.title('Original image')

  plt.subplot(1, 2, 2)
  plt.imshow(preds[index].squeeze().cpu().numpy(), cmap='gray')
  plt.title('Predicted mask')

  plt.show()

show_predicted_mask(20)